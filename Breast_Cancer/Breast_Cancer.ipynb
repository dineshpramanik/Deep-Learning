{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "eEJcB70gNDw7",
    "outputId": "f3378bf4-eb43-4f1c-befb-aae1df5e8054"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-64d38e5e-f7b2-47a5-9bea-7979288f1e4d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-64d38e5e-f7b2-47a5-9bea-7979288f1e4d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Breast_Cancer.csv to Breast_Cancer (1).csv\n"
     ]
    }
   ],
   "source": [
    "#Uploading Dataset in Google Colab\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQSu7ajbOI0F"
   },
   "outputs": [],
   "source": [
    "#Importing neccessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JX-ihN__D2e5"
   },
   "outputs": [],
   "source": [
    "#Reading Dataset\n",
    "\n",
    "df = pd.read_csv(io.StringIO(uploaded['Breast_Cancer.csv'].decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Breast_Cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "4ioGrDwjE8QZ",
    "outputId": "d2122936-e63d-497c-d1ca-4478844d1078"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q14yfWIyFO2Q",
    "outputId": "cba392b0-e665-44cf-8ee3-969cd57d109b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "6-pOnOsWPIs8",
    "outputId": "9ee59bde-0ad0-454f-c26e-41a5f0a18ab7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'diagnosis' is Output variable\n",
    "\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "XxJ3nk0PFQrU",
    "outputId": "6a150bfe-ca39-44b6-e6ea-f96e563c823f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13bf5450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting no. of Malignant and Benign patient\n",
    "\n",
    "sns.countplot(df['diagnosis'], label= 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjCMizIBO9_T"
   },
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 32', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 140.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gp9FRo0vPerM"
   },
   "outputs": [],
   "source": [
    "#Storing the Input variable in 'X' and Output variable in 'y'\n",
    "\n",
    "X= df.iloc[:, 2:].values\n",
    "y= df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HflSklfjPsvk"
   },
   "outputs": [],
   "source": [
    "#Encoding Categorical data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae809x6QQJcH"
   },
   "outputs": [],
   "source": [
    "y= le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZB0pNG5Qg6l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9t-SARlXQh-9"
   },
   "outputs": [],
   "source": [
    "#Spliting the Dataset into Training and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tjs5BARUQza5"
   },
   "outputs": [],
   "source": [
    "#Performing Feature scaling\n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "ss= StandardScaler()\n",
    "\n",
    "X_train= ss.fit_transform(X_train)\n",
    "X_test= ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DE-4Xwrc93Co",
    "outputId": "b9b7b50c-0a40-4c22-fe93-d3dc9bef5a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_dJvRhsj-HxT",
    "outputId": "0eaba2ca-aa9f-4088-8baa-215505dba505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31650044, -1.37776215, -0.33597328, ...,  0.0423046 ,\n",
       "        -0.81860603,  0.05312956],\n",
       "       [ 0.66779784, -0.1239742 ,  0.76191   , ...,  0.92160986,\n",
       "        -0.21942973,  1.16206366],\n",
       "       [ 0.02713032, -0.76582161, -0.04185213, ..., -0.58204784,\n",
       "        -0.28892183, -0.65109966],\n",
       "       ...,\n",
       "       [-0.87271633,  0.46956211, -0.79743923, ...,  0.45224068,\n",
       "         0.08015841,  0.61533833],\n",
       "       [-0.29029131, -0.75661949, -0.32245047, ..., -0.10856406,\n",
       "         0.72257424,  0.60359227],\n",
       "       [-0.64265845, -1.21672516, -0.69855367, ..., -0.45449524,\n",
       "         0.29172324, -0.94261532]])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "NcQ4DBKMRP3l",
    "outputId": "007c213c-0525-4b15-c218-35be1be8700a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PoTSOPUW9vK4",
    "outputId": "195082ff-3b5e-407c-b356-b335e1318ee6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Keras library\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "GeshumM9-TgF",
    "outputId": "0a4c6905-be05-40ad-aa6c-04614e1663e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=30, activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Adding input and first hidden layer\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(input_dim= 30, output_dim= 16, init= 'uniform', activation='relu'))\n",
    "\n",
    "#Adding second hidden layer\n",
    "classifier.add(Dense(output_dim= 16, init= 'uniform', activation='relu'))\n",
    "\n",
    "#Adding Output layer\n",
    "classifier.add(Dense(output_dim= 1, init= 'uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9hnJI3cM1bi"
   },
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bbEOjoTyN32V",
    "outputId": "1ce4a873-ed04-4061-b89d-82c94027f903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "398/398 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.6658\n",
      "Epoch 2/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6909 - accuracy: 0.6407\n",
      "Epoch 3/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6887 - accuracy: 0.6432\n",
      "Epoch 4/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.6854 - accuracy: 0.6508\n",
      "Epoch 5/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6808 - accuracy: 0.6884\n",
      "Epoch 6/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.6742 - accuracy: 0.7387\n",
      "Epoch 7/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6654 - accuracy: 0.8216\n",
      "Epoch 8/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.6539 - accuracy: 0.8543\n",
      "Epoch 9/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.6390 - accuracy: 0.8945\n",
      "Epoch 10/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.6211 - accuracy: 0.9171\n",
      "Epoch 11/150\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.5988 - accuracy: 0.9246\n",
      "Epoch 12/150\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.5732 - accuracy: 0.9296\n",
      "Epoch 13/150\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.5442 - accuracy: 0.9322\n",
      "Epoch 14/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.5120 - accuracy: 0.9397\n",
      "Epoch 15/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.4786 - accuracy: 0.9372\n",
      "Epoch 16/150\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.4441 - accuracy: 0.9347\n",
      "Epoch 17/150\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.4101 - accuracy: 0.9322\n",
      "Epoch 18/150\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.3789 - accuracy: 0.9322\n",
      "Epoch 19/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.3490 - accuracy: 0.9322\n",
      "Epoch 20/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.3217 - accuracy: 0.9347\n",
      "Epoch 21/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.2972 - accuracy: 0.9347\n",
      "Epoch 22/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.2757 - accuracy: 0.9372\n",
      "Epoch 23/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.2555 - accuracy: 0.9397\n",
      "Epoch 24/150\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.2379 - accuracy: 0.9422\n",
      "Epoch 25/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.2217 - accuracy: 0.9472\n",
      "Epoch 26/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.2077 - accuracy: 0.9472\n",
      "Epoch 27/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1949 - accuracy: 0.9523\n",
      "Epoch 28/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.1835 - accuracy: 0.9573\n",
      "Epoch 29/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1725 - accuracy: 0.9598\n",
      "Epoch 30/150\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1638 - accuracy: 0.9623\n",
      "Epoch 31/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1554 - accuracy: 0.9623\n",
      "Epoch 32/150\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1483 - accuracy: 0.9648\n",
      "Epoch 33/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1418 - accuracy: 0.9648\n",
      "Epoch 34/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1363 - accuracy: 0.9648\n",
      "Epoch 35/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1309 - accuracy: 0.9673\n",
      "Epoch 36/150\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.1264 - accuracy: 0.9673\n",
      "Epoch 37/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1225 - accuracy: 0.9648\n",
      "Epoch 38/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1184 - accuracy: 0.9673\n",
      "Epoch 39/150\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.1151 - accuracy: 0.9724\n",
      "Epoch 40/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1117 - accuracy: 0.9724\n",
      "Epoch 41/150\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.1087 - accuracy: 0.9724\n",
      "Epoch 42/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1060 - accuracy: 0.9724\n",
      "Epoch 43/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1038 - accuracy: 0.9749\n",
      "Epoch 44/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.1013 - accuracy: 0.9749\n",
      "Epoch 45/150\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0992 - accuracy: 0.9749\n",
      "Epoch 46/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0971 - accuracy: 0.9749\n",
      "Epoch 47/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0952 - accuracy: 0.9749\n",
      "Epoch 48/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0935 - accuracy: 0.9774\n",
      "Epoch 49/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0917 - accuracy: 0.9799\n",
      "Epoch 50/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0902 - accuracy: 0.9799\n",
      "Epoch 51/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0886 - accuracy: 0.9799\n",
      "Epoch 52/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0871 - accuracy: 0.9799\n",
      "Epoch 53/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0858 - accuracy: 0.9824\n",
      "Epoch 54/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0843 - accuracy: 0.9824\n",
      "Epoch 55/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0830 - accuracy: 0.9849\n",
      "Epoch 56/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0819 - accuracy: 0.9849\n",
      "Epoch 57/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0806 - accuracy: 0.9849\n",
      "Epoch 58/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0794 - accuracy: 0.9849\n",
      "Epoch 59/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0782 - accuracy: 0.9849\n",
      "Epoch 60/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0771 - accuracy: 0.9849\n",
      "Epoch 61/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0760 - accuracy: 0.9849\n",
      "Epoch 62/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0749 - accuracy: 0.9849\n",
      "Epoch 63/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0738 - accuracy: 0.9849\n",
      "Epoch 64/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0729 - accuracy: 0.9849\n",
      "Epoch 65/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0719 - accuracy: 0.9849\n",
      "Epoch 66/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0711 - accuracy: 0.9849\n",
      "Epoch 67/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0701 - accuracy: 0.9849\n",
      "Epoch 68/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0692 - accuracy: 0.9849\n",
      "Epoch 69/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0685 - accuracy: 0.9849\n",
      "Epoch 70/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0677 - accuracy: 0.9849\n",
      "Epoch 71/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0669 - accuracy: 0.9874\n",
      "Epoch 72/150\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0661 - accuracy: 0.9874\n",
      "Epoch 73/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0654 - accuracy: 0.9874\n",
      "Epoch 74/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0647 - accuracy: 0.9874\n",
      "Epoch 75/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0641 - accuracy: 0.9874\n",
      "Epoch 76/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0634 - accuracy: 0.9874\n",
      "Epoch 77/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0629 - accuracy: 0.9874\n",
      "Epoch 78/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0623 - accuracy: 0.9874\n",
      "Epoch 79/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0617 - accuracy: 0.9874\n",
      "Epoch 80/150\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0611 - accuracy: 0.9874\n",
      "Epoch 81/150\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0606 - accuracy: 0.9874\n",
      "Epoch 82/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0601 - accuracy: 0.9874\n",
      "Epoch 83/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0596 - accuracy: 0.9874\n",
      "Epoch 84/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0591 - accuracy: 0.9874\n",
      "Epoch 85/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0587 - accuracy: 0.9874\n",
      "Epoch 86/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0582 - accuracy: 0.9874\n",
      "Epoch 87/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0578 - accuracy: 0.9874\n",
      "Epoch 88/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0574 - accuracy: 0.9874\n",
      "Epoch 89/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0569 - accuracy: 0.9874\n",
      "Epoch 90/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0565 - accuracy: 0.9874\n",
      "Epoch 91/150\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0561 - accuracy: 0.9874\n",
      "Epoch 92/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0557 - accuracy: 0.9874\n",
      "Epoch 93/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0553 - accuracy: 0.9874\n",
      "Epoch 94/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0549 - accuracy: 0.9874\n",
      "Epoch 95/150\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0545 - accuracy: 0.9874\n",
      "Epoch 96/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0542 - accuracy: 0.9874\n",
      "Epoch 97/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0538 - accuracy: 0.9874\n",
      "Epoch 98/150\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0534 - accuracy: 0.9874\n",
      "Epoch 99/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0530 - accuracy: 0.9874\n",
      "Epoch 100/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0527 - accuracy: 0.9874\n",
      "Epoch 101/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0523 - accuracy: 0.9874\n",
      "Epoch 102/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0520 - accuracy: 0.9874\n",
      "Epoch 103/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0517 - accuracy: 0.9874\n",
      "Epoch 104/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0513 - accuracy: 0.9874\n",
      "Epoch 105/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0510 - accuracy: 0.9874\n",
      "Epoch 106/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0507 - accuracy: 0.9874\n",
      "Epoch 107/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0504 - accuracy: 0.9874\n",
      "Epoch 108/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0501 - accuracy: 0.9874\n",
      "Epoch 109/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0498 - accuracy: 0.9874\n",
      "Epoch 110/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0495 - accuracy: 0.9874\n",
      "Epoch 111/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0492 - accuracy: 0.9874\n",
      "Epoch 112/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0489 - accuracy: 0.9874\n",
      "Epoch 113/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0487 - accuracy: 0.9874\n",
      "Epoch 114/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0484 - accuracy: 0.9874\n",
      "Epoch 115/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0481 - accuracy: 0.9899\n",
      "Epoch 116/150\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0479 - accuracy: 0.9899\n",
      "Epoch 117/150\n",
      "398/398 [==============================] - 0s 67us/step - loss: 0.0476 - accuracy: 0.9899\n",
      "Epoch 118/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0474 - accuracy: 0.9899\n",
      "Epoch 119/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0471 - accuracy: 0.9899\n",
      "Epoch 120/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0469 - accuracy: 0.9899\n",
      "Epoch 121/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0466 - accuracy: 0.9899\n",
      "Epoch 122/150\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0464 - accuracy: 0.9899\n",
      "Epoch 123/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0462 - accuracy: 0.9899\n",
      "Epoch 124/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0459 - accuracy: 0.9899\n",
      "Epoch 125/150\n",
      "398/398 [==============================] - 0s 62us/step - loss: 0.0457 - accuracy: 0.9899\n",
      "Epoch 126/150\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0455 - accuracy: 0.9899\n",
      "Epoch 127/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0453 - accuracy: 0.9899\n",
      "Epoch 128/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 129/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0449 - accuracy: 0.9899\n",
      "Epoch 130/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0446 - accuracy: 0.9899\n",
      "Epoch 131/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0444 - accuracy: 0.9899\n",
      "Epoch 132/150\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0442 - accuracy: 0.9899\n",
      "Epoch 133/150\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0440 - accuracy: 0.9899\n",
      "Epoch 134/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0437 - accuracy: 0.9899\n",
      "Epoch 135/150\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0435 - accuracy: 0.9899\n",
      "Epoch 136/150\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0433 - accuracy: 0.9899\n",
      "Epoch 137/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0431 - accuracy: 0.9899\n",
      "Epoch 138/150\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0429 - accuracy: 0.9899\n",
      "Epoch 139/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0427 - accuracy: 0.9899\n",
      "Epoch 140/150\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0425 - accuracy: 0.9899\n",
      "Epoch 141/150\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0423 - accuracy: 0.9899\n",
      "Epoch 142/150\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0420 - accuracy: 0.9899\n",
      "Epoch 143/150\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0419 - accuracy: 0.9899\n",
      "Epoch 144/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0416 - accuracy: 0.9899\n",
      "Epoch 145/150\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0414 - accuracy: 0.9899\n",
      "Epoch 146/150\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0412 - accuracy: 0.9899\n",
      "Epoch 147/150\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0410 - accuracy: 0.9899\n",
      "Epoch 148/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0409 - accuracy: 0.9899\n",
      "Epoch 149/150\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0406 - accuracy: 0.9899\n",
      "Epoch 150/150\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0404 - accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f84a0439668>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with batch_size=100, epochs=150\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8FqPVdWONlm"
   },
   "outputs": [],
   "source": [
    "#Predicting the Test set\n",
    "y_pred= classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9ZHFaNzPEIk"
   },
   "outputs": [],
   "source": [
    "#Values greater than 0.5 classify as 1; values less than or equal to 0.5 classify as 0\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4LtFLWMPJRg"
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Zy_elIB6PcWV",
    "outputId": "7ed31ec7-8154-4b91-a01e-2488cffc4a29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,   2],\n",
       "       [  1,  68]])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gc9lu01-U4oE",
    "outputId": "798aa0fb-1712-4b3a-a973-afd19095edf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "\n",
    "(100+68)/171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "sJcAzt6GPdHD",
    "outputId": "13d0a135-aea4-4993-adf7-ff4a65196a01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f84a028b208>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_FZ8SoCPjmB"
   },
   "outputs": [],
   "source": [
    "##Model classification using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zrrjH92UuDs"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NY3GNtGWVfL0"
   },
   "outputs": [],
   "source": [
    "#Function to build classifier\n",
    "\n",
    "def build_classifier():\n",
    "\n",
    "  #Adding input and first hidden layer\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(input_dim= 30, output_dim= 16, init= 'uniform', activation='relu'))\n",
    "\n",
    "  #Adding second hidden layer\n",
    "  classifier.add(Dense(output_dim= 16, init= 'uniform', activation='relu'))\n",
    "\n",
    "  #Adding Output layer\n",
    "  classifier.add(Dense(output_dim= 1, init= 'uniform', activation='sigmoid'))\n",
    "\n",
    "  #Compile classifier\n",
    "  classifier.compile(optimizer='Adam', metrics=['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEnUf-J5WStd"
   },
   "outputs": [],
   "source": [
    "#Building classifier and predicting accuracy using Cross validation\n",
    "\n",
    "classifier = KerasClassifier(build_fn= build_classifier, batch_size=100, epochs= 100)\n",
    "accuracy = cross_val_score(estimator= classifier, X=X_train, y=y_train, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "y5BKrl7rXA4g",
    "outputId": "5c40efac-f330-478a-cedc-0a171d4aa213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97500002, 0.97500002, 0.94999999, 0.94999999, 0.94999999,\n",
       "       0.97500002, 0.97500002, 1.        , 0.97435898, 0.97435898])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D0ZXAe_pXJiH",
    "outputId": "f67a510b-a4e9-4e35-d3c8-db0743cc1849"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698718011379241"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r-QUT5eqXlAw",
    "outputId": "ae8b8945-3321-4273-ced0-ac593770e565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014959409668426816"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCYlsqaVX136"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Breast Cancer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
